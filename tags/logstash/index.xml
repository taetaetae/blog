<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>logstash - Tag - 👨‍💻꿈꾸는 태태태의 공간</title><link>https://taetaetae.github.io/tags/logstash/</link><description>logstash - Tag - 👨‍💻꿈꾸는 태태태의 공간</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 10 Feb 2019 14:37:31 +0000</lastBuildDate><atom:link href="https://taetaetae.github.io/tags/logstash/" rel="self" type="application/rss+xml"/><item><title>누구나 할 수 있는 엑세스 로그 분석 따라 해보기 (by Elastic Stack)</title><link>https://taetaetae.github.io/2019/02/10/access-log-to-elastic-stack/</link><pubDate>Sun, 10 Feb 2019 14:37:31 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2019/02/10/access-log-to-elastic-stack/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/access-log-to-elastic-stack/elastic_stack.jpg" referrerpolicy="no-referrer">
            </div>필자가 Elastic Stack을 알게된건 2017년 어느 여름 동기형이 공부하고 있는것을 보고 호기심에 따라하며 시작하게 되었다. 그때까지만 해도 버전이 2.x 였는데 지금 글을 쓰고있는 2019년 2월초 최신버전이 6.6이니 정말 빠르게 변화하는것 같다. 빠르게 변화하는 버전만큼 사람들의 관심도 (드라마틱하게는 아니지만) 꾸준히 늘어나 개인적으로, 그리고 실무에서도 활용하는 범위가 많아지고 있는것 같다.
 trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"elasticsearch","geo":"KR","time":"today 5-y"}],"category":0,"property":""}, {"exploreQuery":"date=today%205-y&geo=KR&q=elasticsearch","guestPath":"https://trends.google.co.kr:443/trends/embed/"});  그래서 그런지 최근들어 (아주 코딱지만큼 조금이라도 더 해본) 필자에게 Elastic Stack 사용방법에 대해 물어보는 주변 지인들이 늘어나고 있다. 그리고 예전에 한창 공부했을때의 버전보다 많이 바꼈기에 이 기회에 &ldquo;그대로 따라만 하면 Elastic Stack을 구성할 수 있을만한 글&quot;을 써보고자 한다. 사실 필자가 예전에 &ldquo;도큐먼트를 보기엔 너무 어려워 보이는 느낌적인 느낌&rdquo; 때문에 삽질하며 구성한 힘들었던 기억을 되살려 최대한 심플하고 처음 해보는 사람도 따라하기만 하면 &ldquo;아~ 이게 Elastic Stack 이구나!&rdquo;, &ldquo;이런식으로 돌아가는 거구나!&rdquo; 하는 도움을 주고 싶다.
 + 그러면서 최신버전도 살펴보고&hellip; 1석2조, 이런게 바로 블로그를 하는 이유이지 않을까? 다시한번 말하지만 도큐먼트가 최고 지침서이긴 하다&hellip;
 Elastic 공식 홈페이지에 가면 각 제품군들에 대해 그림으로 된 자세한 설명과 도큐먼트가 있지만 이들을 어떤식으로 조합하여 사용하는지에 대한 전체적인 흐름을 볼 수 있는 곳은 없어 보인다. (지금 보면 도큐먼트가 그 어디보다 설명이 잘되어 있다고 생각되지만 사전 지식이 전혀없는 상태에서는 봐도봐도 어려워 보였다.) 이번 포스팅에서는 Apache access log를 Elasticsearch에 인덱싱 하는 방법에 대해 설명해보고자 한다.
전체적인 흐름 필자는 글보다는 그림을 좋아하는 편이라 전체적인 흐름을 그림으로 먼저 보자.
  외부에서의 접근이 발생하면 apache 웹서버에서 설정한 경로에 access log가 파일로 생성이 되거나 있는 파일에 추가가 된다. 해당 파일에는 한줄당 하나의 엑세스 정보가 남게 된다. fileBeat에서 해당 파일을 트래킹 하고 있다가 라인이 추가되면 이 정보를 logstash 에게 전달해준다. logastsh 는 filebeat에서 전달한 정보를 특정 port로 input 받는다. 받은 정보를 filter 과정을 통해 각 정보를 분할 및 정제한다. (ip, uri, time 등) 정리된 정보를 elasticsearch 에 ouput 으로 보낸다. (정확히 말하면 인덱싱을 한다.) elasticsearch 에 인덱싱 된 정보를 키바나를 통해 손쉽게 분석을 한다.  한번의 설치고 일련의 과정이 뚝딱 된다면 너무 편하겠지만, 각각의 레이어가 나뉘어져있는 이유는 하는 역활이 전문적으로(?) 나뉘어져 있고 각 레이어에서는 세부 설정을 통해 보다 효율적으로 데이터를 관리할 수 있기 때문이다.
 beats라는 레이어가 나오기 전에는 logstash에서 직접 file을 바라보곤 했었는데 beats가 logstash 보다 가벼운 shipper 목적으로 나온 agent 이다보니 통상 logstash 앞단에 filebeat를 위치시키곤 한다고 한다.
 전체적인 그림은 위와 같고, 이제 이 글을 보고있는 여러분들이 따라할 차례이다. 각 레이어별로 하나씩 설치를 해보며 구성을 해보자. 설치순서는 데이터 흐름의 순서에 맞춰 다음과 같은 순서로 설치를 해야 효율적으로 볼수가 있다. (아래순서대로 하지 않을경우 설치/시작/종료 를 각각의 타이밍에 맞추어 해줘야 할것 같아 복잡할것같다.)
elasticsearch → logstash → kibana → filebeat 이 포스팅은 CentOS 7.4에서 Java 1.8, apache 2.2가 설치되어있다는 가정하에 보면 될듯하다. 또한 각 레이어별 설명은 구글링을 하거나 Elastic 공식 홈페이지에 가보면 자세히 나와있으니 기본 설명은 안하는것으로 하고, 각 레이어의 세부 설정은 하지 않는것으로 한다.
Elasticsearch 공식 홈페이지
다운받고 압축풀고 심볼릭 경로 만들고 (심볼릭 경로는 선택사항) $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.6.0.tar.gz $ tar zxvf elasticsearch-6.6.0.tar.gz $ ln -s elasticsearch-6.6.0 elasticsearch 설정 파일을 열고 추가해준다. $ cd elasticsearch/conf $ vi elasticsearch.yml path.data: /~~~/data/elasticsearch (기본경로에서 변경할때추가) path.logs: /~~~/logs/elasticsearch network.host: 0.0.0.0 # 외부에서 접근이 가능하도록 (실제 ip를 적어줘도 됨) elasticsearch 의 시작과 종료를 조금이나마 편하게 하기위해 스크립트를 작성해줌 (이것또한 선택사항) $ cd ../bin $ echo &#39;.]]></description></item><item><title>내 서버에는 누가 들어오는걸까? (실시간 user-agent 분석기)</title><link>https://taetaetae.github.io/2018/04/10/apache-access-log-user-agent/</link><pubDate>Tue, 10 Apr 2018 23:20:19 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2018/04/10/apache-access-log-user-agent/</guid><description><![CDATA[Desktop 및 스마트폰의 대중화로 다양한 OS와 브라우저들을 사용하게 되었다. 이때, 내가 운영하는 웹서버에 들어오는 사람들은 무슨 기기로 접속을 하는 것일까? 혹여 특정 OS의 특정 브라우저에서만 안되는 버그를 잡기 위해 몇일밤을 고생하며 겨우 수정했는데&hellip; 과연 그 OS의 브라우저에서는 접속은 하기나 하는걸까? (ㅠㅠ) 만약, 접속 사용자의 Device 정보를 알고있다면 고생하며 버그를 잡기 전에 먼저 해당 Device 사용율을 체크해 볼수도 있고(수정이 아닌 간단한 얼럿으로 해결한다거나?) 비지니스 모델까지 생각해야하는 서비스라면 타겟팅을 정하는 등 다양한 활용도가 높은 것이 바로 User-Agent라고 한다(이하 UA). 일반 Apache 를 웹서버로 운영하고 있다고 가정을 하고 어떻게 분석을 할수 있었는지, 그리고 분석을 하며 좀더 우아한(?) 방법은 없는지 알아 보고자 한다.
User-Agent가 뭐야? 백문이 불여일타(?)라 했던가, 우선 http://www.useragentstring.com 를 들어가보자. 그러면 자신의 OS 및 브라우저 등 정보를 파싱해서 보여주는데 위키백과에 따르면 &lsquo;사용자를 대신하여 일을 수행하는 소프트웨어 에이전트&rsquo;라고 한다. 즉, UA만 알아도 어떤 기기/브라우저를 사용하는지 알 수 있다는것. mozilla에 가보면 스팩 등 다양한 UA를 볼수가 있는데 특히 맨 아래보면 기기/브라우저별로 지원정보가 나와있다. 여기서도 보면 모든 모바일 삼성 브라우저를 제외하고는 전부 지원이 되는걸 확인할수 있다.
출처 : developer.mozilla.org" 출처 : developer.mozilla.org  기존의 방법 그럼 어떻게 내 서버에 들어온 사용자들의 UA를 확인할 수 있을까? (앞서 Apache를 웹서버로 운영한다고 했으니) Apache access log 에는 Apache에서 제공해주는 모듈을 이용해 접속한 클라이언트의 정보가 남겨지곤 한다. 그렇다면 이 access log를 리눅스 명령어든 엑셀로 뽑아서든지 활용해서 정규식으로 포맷팅 하고 그 결과를 다시 그룹화 시키면 얼추 원하는 데이터를 추출해 낼수 있다. ( 버거형들이 만들어둔 정규식을 가져다 사용할수도 있겠다. https://regexr.com/?37l4e ) 하지만, 우선 자동화가 안되어있어 데이터를 구하고 싶을때마다 귀차니즘에 걸릴수 있고 슈퍼 개발자 파워를 기반으로(?) 데이터 추출을 자동화 한들 실시간으로 보고싶을땐 제한사항이 많다.
좀더 나은 방법(?) 실시간 데이터를 모니터링 하는데에는 다양한 오픈소스와 다양한 툴이 있겠지만 경험이 부족한건지 아직까진 ElasticStack 만한걸 못본것 같다. 간단하게 설명을 하면 access log 를 사용하지 않고 front단에서 javascript 로 UA를 구한다음 이러한 정보를 받을수 있는 API를 만들어 그쪽으로 보내면 서버에서 해당 UA를 분석해서 카프카로 보내고 ..!@#$%^blabla&hellip; ^^; 그림으로 보자.
좀더 나은 방법" 좀더 나은 방법  front단에서는 navigator.userAgent를 활용하여 UA를 구할수 있었고, API에서는 UA를 받고 파싱을 하는데 관련 코드는 다음과 같이 작성하였다.
private static final String VERSION_SEPARATOR = &#34;.&#34;; private void userAgentParsingToMap(String userAgent, Map&lt;String, Object&gt; dataMap) { HashMap browser = Browser.lookup(userAgent); HashMap os = OS.lookup(userAgent); HashMap device = Device.lookup(userAgent); dataMap.put(&#34;browserName&#34;, browser.get(&#34;family&#34;)); dataMap.put(&#34;browserVersion&#34;, getVersion(browser)); dataMap.put(&#34;osName&#34;, os.get(&#34;family&#34;)); dataMap.put(&#34;osVersion&#34;, getVersion(os)); dataMap.put(&#34;deviceModel&#34;, device.get(&#34;model&#34;)); dataMap.put(&#34;deviceBrand&#34;, device.get(&#34;brand&#34;)); } private String getVersion(HashMap dataMap) { String majorVersion = (String)dataMap.get(&#34;major&#34;); if (StringUtils.isEmpty(majorVersion)) { return StringUtils.EMPTY; } String minorVersion = (String)dataMap.get(&#34;minor&#34;); String pathVersion = (String)dataMap.get(&#34;path&#34;); StringBuffer sb = new StringBuffer(); sb.append(majorVersion); if (!StringUtils.isEmpty(minorVersion)) { sb.append(VERSION_SEPARATOR); sb.append(minorVersion); } if (!StringUtils.isEmpty(pathVersion)) { sb.append(VERSION_SEPARATOR); sb.append(pathVersion); } return sb.toString(); } 참고로 Java단에서 UA를 파싱하는 parser가 여러가지가 있는데 그중 uap_clj라는 모듈이 그나마 잘 파싱이 되어서 사용하게 되었다.
 모듈별 비교     모듈 Browser OS Device     eu.bitwalker.useragentutils.UserAgent O 불명확함 (Android 5.x) X   net.sf.uadetector.UserAgentStringParser O O 불명확함 (Smartphone)   uap_clj.java.api.* O O O     Parsing 비교  UA    &#34;Mozilla/5.0 (Linux; Android 5.1.1; Nexus 6 Build/LYZ28E) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36&#34;  결과   - Browser : {patch=3239, family=Chrome Mobile, major=63, minor=0} - OS : {patch=1, patch_minor=, family=Android, major=5, minor=1} - Device : {model=Nexus 6, family=Nexus 6, brand=Generic_Android} 위와 같이 구성을 하면 Elasticsearch에 인덱싱된 데이터를 Kibana에서 입맛에 맞게 실시간으로 볼수있게 되었다!]]></description></item><item><title>아파치 엑세스 로그를 엘라스틱서치에 인덱싱 해보자.</title><link>https://taetaetae.github.io/2018/01/25/apache-access-log-to-es/</link><pubDate>Thu, 25 Jan 2018 21:18:35 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2018/01/25/apache-access-log-to-es/</guid><description><![CDATA[apache access log 를 분석하고 싶은 상황이 생겼다. 아니 그보다 apache access에 대해서 실시간으로 보고싶었고, log를 검색 &amp; 데이터를 가공하여 유의미한 분석결과를 만들어 보고 싶었다. 그에 생각한것이 (역시) ElasticStack.처음에 생각한 방안은 아래 그림처럼 단순했다. 처음 생각한 단순한 구조" 처음 생각한 단순한 구조 
하지만, 내 단순한(?) 예상은 역시 빗나갔고 logstash에서는 다음과 같은 에러를 내뱉었다.
 retrying individual bulk actions that failed or were rejected by the previous bulk request
 request가 많아짐에 따라 elasticsearch가 버벅거리더니 logstash에서 대량작업은 거부하겠다며 인덱싱을 멈췄다. 고민고민하다 elasticsearch에 인덱싱할때 부하가 많이 걸리는 상황에서 중간에 버퍼를 둔 경험이 있어서 facebook그룹에 문의를 해봤다. https://www.facebook.com/groups/elasticsearch.kr/?multi_permalinks=1566735266745641 역시 나보다 한참을 앞서가시는 분들은 이미 에러가 뭔지 알고 있으셨고, 중간에 버퍼를 두고 하니 잘된다는 의견이 있어 나도 따라해봤다. 물론 답변중에 나온 redis가 아닌 기존에도 비슷한 구조에서 사용하고 있던 kafka를 적용. 아, 그전에 현재구성은 Elasticsearch 노드가 총 3대로 클러스터 구조로 되어있는데 노드를 추가로 늘리며 스케일 아웃을 해보기전에 할수있는 마지막 방법이다 생각하고 중간에 kafka를 둬서 부하를 줄여보고 싶었다. (언제부턴가 마치 여러개의 톱니바퀴가 맞물려 돌아가는듯한 시스템 설계를 하는게 재밌었다.) 아래 그림처럼 말이다.
그나마 좀더 생각한 구조" 그나마 좀더 생각한 구조  그랬더니 거짓말 처럼 에러하나 없이 잘 인덱싱이 될수 있었다. logstash가 양쪽에 있는게 약간 걸리긴 하지만, 처음에 생각한 구조보다는 에러가 안나니 다행이라 생각한다.
이 구조를 적용하면서 얻은 Insight가 있기에, 각 항목별로 적어 보고자 한다. ( 이것만 적어놓기엔 너무 없어보여서.. )
access log 를 어떻게 분석하여 인덱싱 할것인가? apache 2.x를 사용하고 별도의 로그 포맷을 정하지 않으면 아래와 같은 access log가 찍힌다. 123.1.1.1 - - [25/Jan/2018:21:55:35 +0900] &quot;GET /api/test?param=12341234 HTTP/1.1&quot; 200 48 1144 &quot;http://www.naver.com/&quot; &quot;Mozilla/5.0 (iPhone; CPU iPhone OS 11_1_2 like Mac OS X) AppleWebKit/604.3.5 (KHTML, like Gecko) Mobile/15B202 NAVER(inapp; blog; 100; 4.0.44)&quot; 그럼 이 로그를 아무 포맷팅 없이 로깅을 하면 그냥 한줄의 텍스트가 인덱싱이 된다. 하지만 이렇게 되면 elasticsearch 데이터를 다시 재가공하거나 별도의 작업이 필요할수도 있으니 중간에 있는 logstash에게 일을 시켜 좀더 nice 한 방법으로 인덱싱을 해보자. 바로 logstash 의 filter 기능이다. 그중 Grok filter 라는게 있는데 패턴을 적용하여 row data 를 필터링하는 기능이다. 조금 찾아보니 너무 고맙게도 아파치 필터 예제가 있어 수정하여 적용할수 있었다. http://grokconstructor.appspot.com/do/match?example=2 그래서 적용한 필터설정은 다음과 같다.
filter { grok { match =&gt; { message =&gt; &#34;%{IP:clientIp} (?:-|) (?:-|) \[%{HTTPDATE:timestamp}\] \&#34;(?:%{WORD:httpMethod} %{URIPATH:uri}%{GREEDYDATA}(?: HTTP/%{NUMBER})?|-)\&#34; %{NUMBER:responseCode} (?:-|%{NUMBER})&#34; } } } 이렇게 하고 elasticsearch 에 인덱싱을 하면 키바나에서 다음과 같이 볼수 있다. 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log" 키바나에 내가 원하는 구조대로 이쁘게 들어가 있는 access log 
각 필드가 아닌 한줄로 인덱싱이 되어버린다. Elasticsearch 에 인덱싱이 되긴 하는데 로그 한줄이 통째로 들어가 버린다. message라는 이름으로&hellip; 알고보니 현재 구조는 logstash가 kafka 앞 뒤에 있다보니 producer logstash 와 consumer logstash 의 codec이 맞아야 제대로 인덱싱이 될수 있었다. 먼저 access log에서 kafka 로 produce 하는 logstash 에서는 output 할때 codec 을 맞춰주고
output { kafka { bootstrap_servers =&gt; &#34;123.1.2.3:9092,123.1.2.4:9092&#34; topic_id =&gt; &#34;apache-log&#34; codec =&gt; json{} } } kafka 에서 consume 하는 logstash 에서는 input 에서 codec 을 맞춰준다.
input { kafka { bootstrap_servers =&gt; &#34;123.1.2.3:9092,123.1.2.4:9092&#34; topic_id =&gt; &#34;apache-log&#34; codec =&gt; json{} } } 그렇게 되면 codec이 맞아 각 필드로 이쁘게 인덱싱을 할수 있게 되었다.
필요없는 uri는 제외하고 인덱싱할수 있을까? /으로는 uri 라던지 /server-status같이 알고있지만 인덱싱은 하기 싫은 경우는 간단하게 아래처럼 if문으로 제외시킬수 있었다.]]></description></item></channel></rss>