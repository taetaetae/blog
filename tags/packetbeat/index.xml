<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>packetbeat - Tag - 👨‍💻꿈꾸는 태태태의 공간</title><link>https://taetaetae.github.io/tags/packetbeat/</link><description>packetbeat - Tag - 👨‍💻꿈꾸는 태태태의 공간</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 08 Sep 2019 18:11:34 +0000</lastBuildDate><atom:link href="https://taetaetae.github.io/tags/packetbeat/" rel="self" type="application/rss+xml"/><item><title>네트워크 모니터링이 궁금할땐 ? Packetbeat !</title><link>https://taetaetae.github.io/2019/09/08/network-monitor-by-packetbeat/</link><pubDate>Sun, 08 Sep 2019 18:11:34 +0000</pubDate><author>Author</author><guid>https://taetaetae.github.io/2019/09/08/network-monitor-by-packetbeat/</guid><description><![CDATA[<div class="featured-image">
                <img src="/images/network-monitor-by-packetbeat/packetbeat_rgb.png" referrerpolicy="no-referrer">
            </div>모니터링은 서비스 로직 개발 만큼 한번씩 고민해보고 경험해 봤을 중요한 영역이라 할 수 있다. 그중 웹서버에서 제공해주는 엑세스 로그는 운영하고 있는 웹서비스에 대해 여러가지 측면에서 분석할 수 있는 가장 강력한 아이템 중에 하나라고 생각한다. 이를 통해 사용자들이 어떤 url을 많이 호출하고, 어떤 user-agent형태를 사용하는지 알게 되면 그에 따라 서비스 전략을 변경할수도 있고 악의적으로 공격적인 요청에 대해 웹서버단에서 차단을 할 수 있기 때문이다. 이렇게 inbound 트래픽(외부에서 들어오는 요청)에 대해서는 엑세스 로그를 잘 분석하면 기존의 웹 어플리케이션과는 전혀 무관하게 모니터링이 가능하지만 반대로 outbund 트래픽(외부로 나가는 요청)에 대해서는 어떤식으로 모니터링을 할 수 있을까?
월급통장의 inbound 트래픽보다 outbound 트래픽이 너무 많은 요즘&hellip;이미지 출처 : https://www.app24moa.com/feedDetail/2/2002" 월급통장의 inbound 트래픽보다 outbound 트래픽이 너무 많은 요즘&hellip;
이미지 출처 : https://www.app24moa.com/feedDetail/2/2002  예컨데, 날씨 서비스를 하기 위해 외부에서 서울날씨라는 페이지를 조회했을 경우 기상청 API에서 넘겨받은 데이터를 가공하여 보여준다고 가정해보자. 이때 기상청에서 제공해주는 특정 API중에 어느 하나가 늦게 응답이 온다거나, 특정시간대에 에러응답을 받을경우 과연 이를 어떤식으로 모니터링 할수 있을까? 어플리케이션 코드에 모니터링을 위한 코드를 추가할 것인가? 혹 하나의 서버에서 A모듈은 java로, B모듈은 python으로 개발되었을 경우 각각 모듈마다 모니터링을 위한 코드를 추가하는 식으로 하다보면 비지니스 로직을 방해하거나 오히려 추가한 코드 또한 관리해야 하는 배보다 배꼽이 더 커져버릴 상황도 생길수 있다. 어플리케이션의 비지니스 로직과는 무관하게 서버 자체에서 외부로 나가는 네트워크 트래픽에 대해 모니터링을 할 수 있는 가벼우면서도 심플한 모듈을 찾고 싶었다. 어플리케이션의 개발언어가 무엇이든 상관없이 별도의 에이전트 형식으로 띄워두기만 하면 네트워크 트래픽을 수집 및 분석, 나아가서는 모니터링까지 할수있는&hellip; 그래서 찾다보니 역시나 이러한 고민을 누군가는 하고 있었고 오픈소스까지 되어있는 Elastic Stack 의 Beat중 Packetbeat라는 데이터 수집모듈을 알게 되었다.
 역시 내가 하고있는 고민은 이미 누군가 했던 고민들&hellip; 이러한 고민에 대해 해결하는 방법을 보다 빨리 찾는게 경쟁력이 될텐데&hellip;
 이번 포스팅에서는 Packetbeat 에 대해 간단히 알아보고 이를 활용하여 outbound 트래픽에 대해 모니터링을 해보며 어떤식으로 활용할 수 있는지에 대해 알아보고자 한다.
Packetbeat ? ElasticStack 중에 데이터 수집기 플랫폼인 Beats중 네트워크 트래픽 데이터에 대해 수집을 할 수 있는 데이터 수집기를 제공하고 있다. pcap라이브러리를 이용하여 서버의 네트워크 레벨에서 데이터를 수집 및 분석한 후 외부로(Elasticsearch, Logstash, Kafka 등) 전송해주는 경량 네트워크 패킷 분석기라고 공식 홈페이지에 소개되고 있다. 몇번 사용해보면서 느낀 장점들은 다음과 같다.
 설치 및 실행이 너무 간단하다. 설정값 튜닝을 통해 간단하지만, 그러한 간단함에 비해서 너무 강력한 수집이 가능하다. 앞서 이야기 했던 어플리케이션 코드와는 전혀 무관하게 작동한다.  무엇을 해볼것인가?! (a.k.a. 목표) 필자가 운영하는 Daily-DevBlog 라는 서비스가 있다. (갑분 서비스 홍보) 여러 사람들의 rss를 조회하고 파싱해서 메일을 보내주는 서비스 인데, packetbeat 사용 예시를 들기위해 조금 변형하여 모든 rss를 접근하고 가장 최신글의 제목을 출력하는 아주 간단한 python 스크립트로 outbound 트래픽을 발생시켜 보고자 한다. 그리고 packetbeat 를 이용하여 외부로 호출되는 트래픽을 수집하고 Elasticsearch 로 인덱싱 하여 최종적으로는 어느 rss의 속도가 가장 느린지 실행되는 python코드와는 전혀 관련없이 모니터링 해보고자 한다. python 코드는 다음과 같다.
 참고로 필자는 awesome-devblog의 운영자분께 해당 데이터 사용에 대해 허락을 받은 상태이다.
 import requests, yaml, feedparser blog_info_list_yml_url = &#39;https://raw.githubusercontent.com/sarojaba/awesome-devblog/master/db.yml&#39; blog_info_list_yml = requests.get(url=blog_info_list_yml_url).text blog_info_yaml_parse_list = yaml.load(blog_info_list_yml) for blog_info in blog_info_yaml_parse_list : if &#39;rss&#39; not in blog_info.keys() or not blog_info[&#39;rss&#39;]: continue rss_url = blog_info[&#39;rss&#39;] try : parse_feed = feedparser.parse(rss_url) except : continue parse_feed_data = parse_feed.entries[0] print(blog_info[&#39;name&#39;], &#39;|&#39;, parse_feed_data[&#39;title&#39;], &#39;|&#39;, parse_feed_data[&#39;link&#39;]) 위 코드를 실행하면 아래처럼 아주 간단하게 블로그 주인의 이름과 최신글 제목, 링크가 출력이 된다.]]></description></item></channel></rss>